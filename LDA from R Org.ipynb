{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-leader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eat', 'turkey', 'on', 'turkey', 'day', 'holiday'],\n",
       " ['i', 'like', 'to', 'eat', 'cake', 'on', 'holiday'],\n",
       " ['turkey', 'trot', 'race', 'on', 'thanksgiving', 'holiday'],\n",
       " ['snail', 'race', 'the', 'turtle'],\n",
       " ['time', 'travel', 'space', 'race'],\n",
       " ['movie', 'on', 'thanksgiving'],\n",
       " ['movie', 'at', 'air', 'and', 'space', 'museum', 'is', 'cool', 'movie'],\n",
       " ['aspiring', 'movie', 'star']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs = ['eat turkey on turkey day holiday',\n",
    "          'i like to eat cake on holiday',\n",
    "          'turkey trot race on thanksgiving holiday',\n",
    "          'snail race the turtle',\n",
    "          'time travel space race',\n",
    "          'movie on thanksgiving',\n",
    "          'movie at air and space museum is cool movie',\n",
    "          'aspiring movie star']\n",
    "\n",
    "docs = [d.split() for d in raw_docs]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preliminary-classroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat',\n",
       " 'turkey',\n",
       " 'on',\n",
       " 'day',\n",
       " 'holiday',\n",
       " 'i',\n",
       " 'like',\n",
       " 'to',\n",
       " 'cake',\n",
       " 'trot',\n",
       " 'race',\n",
       " 'thanksgiving',\n",
       " 'snail',\n",
       " 'the',\n",
       " 'turtle',\n",
       " 'time',\n",
       " 'travel',\n",
       " 'space',\n",
       " 'movie',\n",
       " 'at',\n",
       " 'air',\n",
       " 'and',\n",
       " 'museum',\n",
       " 'is',\n",
       " 'cool',\n",
       " 'aspiring',\n",
       " 'star']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "vocab = list(dict.fromkeys(\n",
    "    itertools.chain.from_iterable(docs)))\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "private-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 1, 3, 4],\n",
       " [5, 6, 7, 0, 8, 2, 4],\n",
       " [1, 9, 10, 2, 11, 4],\n",
       " [12, 10, 13, 14],\n",
       " [15, 16, 17, 10],\n",
       " [18, 2, 11],\n",
       " [18, 19, 20, 21, 17, 22, 23, 24, 18],\n",
       " [25, 18, 26]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(lambda: len(d))\n",
    "docs = [[d[w] for w in doc] for doc in docs]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moving-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERS\n",
    "K = 2 # number of topics\n",
    "\n",
    "alpha = 1 # hyperparameter. single value indicates symmetric dirichlet prior. \n",
    "# higher=>scatters document clusters\n",
    "\n",
    "eta = .001 # hyperparameter\n",
    "\n",
    "iterations = 3 # iterations for collapsed gibbs sampling.  \n",
    "# This should be a lot higher than 3 in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inner-baptist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# word-topic count matrix. How many times a specific word appears in a topic\n",
    "wt = np.zeros((K, len(vocab)))\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informal-speaker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0, 0],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = defaultdict(int)\n",
    "ta = [[d[w] for w in doc] for doc in docs]\n",
    "ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compressed-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(len(docs)):\n",
    "    for w in range(len(docs[d])):\n",
    "        ta[d][w] = np.random.choice(range(K))\n",
    "        wt[ta[d][w], docs[d][w]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consolidated-estimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 2., 1., 1., 1., 1., 0.,\n",
       "        0., 1., 3., 0., 0., 0., 1., 0., 1., 1., 1.],\n",
       "       [1., 2., 3., 1., 2., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moved-heritage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 1, 1, 1],\n",
       " [0, 1, 1, 1, 0, 1, 0],\n",
       " [1, 0, 1, 1, 1, 1],\n",
       " [0, 0, 0, 0],\n",
       " [1, 1, 0, 0],\n",
       " [0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "induced-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = np.zeros((len(docs), K))\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "smoking-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(len(docs)):\n",
    "    for t in range(K):\n",
    "        dt[d, t] = np.sum(np.array(ta[d]) == t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "swedish-subscription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4.],\n",
       "       [3., 4.],\n",
       "       [1., 5.],\n",
       "       [4., 0.],\n",
       "       [2., 2.],\n",
       "       [3., 0.],\n",
       "       [3., 6.],\n",
       "       [3., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "supreme-energy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 1, 3, 4],\n",
       " [5, 6, 7, 0, 8, 2, 4],\n",
       " [1, 9, 10, 2, 11, 4],\n",
       " [12, 10, 13, 14],\n",
       " [15, 16, 17, 10],\n",
       " [18, 2, 11],\n",
       " [18, 19, 20, 21, 17, 22, 23, 24, 18],\n",
       " [25, 18, 26]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "worldwide-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "0\n",
      "5\n",
      "1\n",
      "6\n",
      "1\n",
      "7\n",
      "1\n",
      "0\n",
      "0\n",
      "8\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "9\n",
      "1\n",
      "10\n",
      "1\n",
      "2\n",
      "1\n",
      "11\n",
      "1\n",
      "4\n",
      "0\n",
      "12\n",
      "0\n",
      "10\n",
      "0\n",
      "13\n",
      "0\n",
      "14\n",
      "1\n",
      "15\n",
      "1\n",
      "16\n",
      "0\n",
      "17\n",
      "0\n",
      "10\n",
      "0\n",
      "18\n",
      "0\n",
      "2\n",
      "0\n",
      "11\n",
      "1\n",
      "18\n",
      "1\n",
      "19\n",
      "1\n",
      "20\n",
      "1\n",
      "21\n",
      "1\n",
      "17\n",
      "0\n",
      "22\n",
      "1\n",
      "23\n",
      "0\n",
      "24\n",
      "0\n",
      "18\n",
      "0\n",
      "25\n",
      "0\n",
      "18\n",
      "0\n",
      "26\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities are not non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2eebf07b23e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mp_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mdenom_b\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_z\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities are not non-negative"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    for d in range(len(docs)):\n",
    "\n",
    "        for w in range(len(docs[d])):\n",
    "\n",
    "            t0 = ta[d][w]\n",
    "            wid = docs[d][w]\n",
    "            \n",
    "            print(t0)\n",
    "            print(wid)\n",
    "\n",
    "            \n",
    "            dt[d, t0] = dt[d, t0] - 1\n",
    "            wt[t0, wid] = wt[t0, wid] - 1\n",
    "            \n",
    "            denom_a = np.sum(dt[d]) + K * alpha\n",
    "            denom_b = np.sum(wt, axis=1) + len(vocab) * eta\n",
    "            \n",
    "            p_z = (wt[:, wid] + eta)  / denom_b * (dt[d] + alpha) / denom_a\n",
    "            t1 = np.random.choice(range(K), p=p_z/np.sum(p_z))\n",
    "            \n",
    "            ta[d][w] = t1\n",
    "\n",
    "            dt[d, t0] = dt[d, t0] + 1\n",
    "            wt[t0, wid] = wt[t0, wid] + 1\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
