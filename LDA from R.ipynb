{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "dea49e27-f418-4f84-a7cb-ff6cb4fa9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from numba import njit, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "d79ad968-15b8-4687-963a-ff633bc02cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs = pd.read_csv(\"billboard.csv\", nrows = 20).dropna()['Lyrics'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "d191e092-a05e-49bb-b26b-019f285cbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create sample documents\n",
    "# doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "# doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "# doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "# doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "# doc_e = \"Health professionals say that brocolli is good for your health.\" \n",
    "\n",
    "# # compile sample documents into a list\n",
    "# raw_docs = [doc_a, doc_b, doc_c, doc_d, doc_e]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "docs = []\n",
    "\n",
    "# loop through document list\n",
    "for i in raw_docs:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    docs.append(stemmed_tokens)\n",
    "    \n",
    "vocab = defaultdict(lambda: len(vocab))\n",
    "docs = [[vocab[w] for w in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "d607bd4d-adac-4f53-a8fe-c8118115c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 15 # number of topics\n",
    "alpha = 1 # hyperparameter. single value indicates symmetric dirichlet prior. higher=>scatters document clusters\n",
    "eta = .001 # hyperparameter\n",
    "iterations = 2000 # iterations for collapsed gibbs sampling.  This should be a lot higher than 3 in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "compressed-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = np.zeros((K, len(vocab)))\n",
    "d = defaultdict(int)\n",
    "ta = [[d[w] for w in doc] for doc in docs]\n",
    "for d in range(len(docs)):\n",
    "    for w in range(len(docs[d])):\n",
    "        ta[d][w] = np.random.choice(K)\n",
    "        ti = ta[d][w]\n",
    "        wi = docs[d][w]\n",
    "        wt[ti, wi] += 1\n",
    "        \n",
    "dt = np.zeros((len(docs), K))\n",
    "for d in range(len(docs)):\n",
    "    for t in range(K):\n",
    "        dt[d, t] = (np.array(ta[d]) == t).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "66c8bf2b-ffae-4041-9aed-7b55d1e9fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(iterations, docs, wt, ta, dt, vocab_len):\n",
    "    for i in range(iterations): # for each pass through the corpus\n",
    "        for di in range(len(docs)): # for each document\n",
    "            for wi in range(len(docs[di])):\n",
    "                t0 = ta[di][wi] # initial topic assignment to token w\n",
    "                word_ID = docs[di][wi] # wordID of token w\n",
    "\n",
    "                dt[di, t0] = dt[di, t0] - 1 # we don't want to include token w in our document-topic count matrix when sampling for token w\n",
    "                wt[t0, word_ID] = wt[t0, word_ID] - 1 # we don't want to include token w in our word-topic count matrix when sampling for token w\n",
    "\n",
    "                ## UPDATE TOPIC ASSIGNMENT FOR EACH WORD -- COLLAPSED GIBBS SAMPLING\n",
    "                denom_a = dt[di, :].sum() + K * alpha # number of tokens in document + number topics * alpha\n",
    "                denom_b = wt.sum(axis = 1) + vocab_len * eta # number of tokens in each topic + # of words in vocab * eta\n",
    "                p_z = (wt[:, word_ID] + eta) / denom_b * (dt[di, :] + alpha) / denom_a # calculating probability word belongs to each topic\n",
    "                prob = p_z / p_z.sum()\n",
    "                prob[prob < 0] = 0\n",
    "                prob[prob > 1] = 1\n",
    "                t1 = np.random.choice(range(K), p = prob) # draw topic for word n from multinomial using probabilities calculated above\n",
    "\n",
    "                ta[di][wi] = t1 # update topic assignment list with newly sampled topic for token w.\n",
    "                dt[di, t1] = dt[di, t1] + 1 # re-increment document-topic matrix with new topic assignment for token w.\n",
    "                wt[t1, word_ID] = wt[t1, word_ID] + 1 #re-increment word-topic matrix with new topic assignment for token w.\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Finished {i}\")\n",
    "    return wt, ta, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "abaa52f4-816a-4895-8384-d3f45faaf3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0\n",
      "Finished 100\n",
      "Finished 200\n",
      "Finished 300\n",
      "Finished 400\n",
      "Finished 500\n",
      "Finished 600\n",
      "Finished 700\n",
      "Finished 800\n",
      "Finished 900\n",
      "Finished 1000\n",
      "Finished 1100\n",
      "Finished 1200\n",
      "Finished 1300\n",
      "Finished 1400\n",
      "Finished 1500\n",
      "Finished 1600\n",
      "Finished 1700\n",
      "Finished 1800\n",
      "Finished 1900\n"
     ]
    }
   ],
   "source": [
    "wt, ta, dt = lda(iterations, docs, wt, ta, dt, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "f68895f7-2572-4c04-80d8-b1d271503e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (dt + alpha) / (dt + alpha).sum(axis = 1).reshape(-1, 1) # topic probabilities per document\n",
    "phi = (wt + eta) / (wt + eta).sum(axis = 1).reshape(-1, 1) # topic probabilities per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "df689683-e9a2-4e8f-bfc8-d0f0797485c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(phi)\n",
    "df.columns = list(vocab.keys())\n",
    "df['topic'] = list(range(15))\n",
    "df = pd.melt(df, id_vars = 'topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e958baa5-3212-4909-bc3f-a813f0f4dbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>0</td>\n",
       "      <td>got</td>\n",
       "      <td>0.326094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>0</td>\n",
       "      <td>babe</td>\n",
       "      <td>0.073837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>0</td>\n",
       "      <td>whoaoh</td>\n",
       "      <td>0.061532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>0</td>\n",
       "      <td>troubl</td>\n",
       "      <td>0.049227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>0</td>\n",
       "      <td>wont</td>\n",
       "      <td>0.049227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>0</td>\n",
       "      <td>mind</td>\n",
       "      <td>0.049227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0</td>\n",
       "      <td>walk</td>\n",
       "      <td>0.030769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0</td>\n",
       "      <td>worri</td>\n",
       "      <td>0.030769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>0</td>\n",
       "      <td>wound</td>\n",
       "      <td>0.018464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>0</td>\n",
       "      <td>yeah</td>\n",
       "      <td>0.018464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic variable     value\n",
       "1695      0      got  0.326094\n",
       "6840      0     babe  0.073837\n",
       "1725      0   whoaoh  0.061532\n",
       "1710      0   troubl  0.049227\n",
       "3810      0     wont  0.049227\n",
       "1680      0     mind  0.049227\n",
       "2010      0     walk  0.030769\n",
       "1740      0    worri  0.030769\n",
       "1755      0    wound  0.018464\n",
       "1845      0     yeah  0.018464"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['topic'] == 0].sort_values(by = 'value', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "31b950ec-4ec7-417d-84ab-ef3ba04dca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>4</td>\n",
       "      <td>well</td>\n",
       "      <td>0.104398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>4</td>\n",
       "      <td>like</td>\n",
       "      <td>0.072278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>4</td>\n",
       "      <td>youv</td>\n",
       "      <td>0.064248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>4</td>\n",
       "      <td>come</td>\n",
       "      <td>0.056218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>4</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.056218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>4</td>\n",
       "      <td>eye</td>\n",
       "      <td>0.056218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>4</td>\n",
       "      <td>doesnt</td>\n",
       "      <td>0.056218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>4</td>\n",
       "      <td>brown</td>\n",
       "      <td>0.048188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>4</td>\n",
       "      <td>make</td>\n",
       "      <td>0.048188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>4</td>\n",
       "      <td>there</td>\n",
       "      <td>0.040158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic variable     value\n",
       "4864      4     well  0.104398\n",
       "2134      4     like  0.072278\n",
       "2794      4     youv  0.064248\n",
       "409       4     come  0.056218\n",
       "1504      4    heart  0.056218\n",
       "1054      4      eye  0.056218\n",
       "7174      4   doesnt  0.056218\n",
       "6229      4    brown  0.048188\n",
       "2404      4     make  0.048188\n",
       "1144      4    there  0.040158"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['topic'] == 4].sort_values(by = 'value', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "71293314-f095-4baf-8034-6fe9757b36d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' sugar pie honey bunch you know that i love you i cant help myself i love you and nobody elsein and out my life you come and you go leaving just your picture behind and i kissed it a thousand timeswhen you snap your finger or wink your eye i come arunning to you im tied to your apron strings and theres nothing that i can docant help myself no i cant help myselfsugar pie honey bunch im weaker than a man should be i cant help myself im a fool in love you seewanna tell you i dont love you tell you that were through and ive tried but every time i see your face i get all choked up insidewhen i call your name girl it starts the flame burning in my heart tearing it all apart no matter how i try my love i cannot hidecause sugar pie honey bunch you know that im weak for you cant help myself i love you and nobody elsesugar pie honey bunch do anything you ask me to cant help myself i want you and nobody elsesugar pie honey bunch you know that i love you i cant help myself i cant help myself '"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bdb03-00a0-44ff-be23-80ef1574e2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
